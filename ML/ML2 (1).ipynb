{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f734da8-4bf8-49aa-a87a-8daf5fed8563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Using cached geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Using cached geographiclib-2.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "Using cached geographiclib-2.1-py3-none-any.whl (40 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "\n",
      "   -------------------- ------------------- 1/2 [geopy]\n",
      "   -------------------- ------------------- 1/2 [geopy]\n",
      "   ---------------------------------------- 2/2 [geopy]\n",
      "\n",
      "Successfully installed geographiclib-2.1 geopy-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60523749",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2015-05-07 19:52:06.0000003'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m~\u001b[39moutliers]\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Step 3: Check the correlation\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(correlation_matrix)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Step 4: Implement linear regression, Ridge, and Lasso regression models\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, na_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mas_array(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interleave(dtype\u001b[38;5;241m=\u001b[39mdtype, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2015-05-07 19:52:06.0000003'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.distance import great_circle\n",
    "\n",
    "# Load your dataset\n",
    "# Replace 'your_dataset.csv' with the actual path to your dataset file\n",
    "data = pd.read_csv('uber.csv')\n",
    "\n",
    "# Check for and drop rows with missing or invalid coordinates\n",
    "data = data.dropna(subset=['pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "'dropoff_longitude'])\n",
    "data = data[(data['pickup_latitude'] >= -90) & (data['pickup_latitude'] <= 90)]\n",
    "data = data[(data['pickup_longitude'] >= -180) & (data['pickup_longitude'] <= 180)]\n",
    "data = data[(data['dropoff_latitude'] >= -90) & (data['dropoff_latitude'] <= 90)]\n",
    "data = data[(data['dropoff_longitude'] >= -180) & (data['dropoff_longitude'] <= 180)]\n",
    "\n",
    "# Calculate the distance for each row and create a new column 'distance'\n",
    "data['distance'] = data.apply(lambda row: great_circle(\n",
    "(row['pickup_latitude'], row['pickup_longitude']),\n",
    "(row['dropoff_latitude'], row['dropoff_longitude'])).miles, axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "\n",
    "# Replace 'updated_dataset.csv' with the desired file name\n",
    "data.to_csv('uber.csv', index=False)\n",
    "# Step 1: Pre-process the dataset\n",
    "# Assume you have columns like 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude','dropoff_latitude', 'distance', and 'price'.\n",
    "\n",
    "# Handle missing values if any\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Encode categorical features if necessary\n",
    "# You may need to convert categorical variables into numerical format using techniques likeone-hot encoding.\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = data[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "'distance']]\n",
    "y = data['fare_amount']\n",
    "# Step 2: Identify outliers\n",
    "# You can use different methods like z-score or IQR to detect outliers.\n",
    "from scipy import stats\n",
    "z_scores = np.abs(stats.zscore(data['distance']))\n",
    "outliers = (z_scores > 3)\n",
    "data = data[~outliers]\n",
    "# Step 3: Check the correlation\n",
    "correlation_matrix = data.corr()\n",
    "print(correlation_matrix)\n",
    "# Step 4: Implement linear regression, Ridge, and Lasso regression models\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Initialize the models\n",
    "linear_reg_model = LinearRegression()\n",
    "ridge_model = Ridge(alpha=100) # You can adjust the alpha parameter\n",
    "lasso_model = Lasso(alpha=0.01) # You can adjust the alpha parameter\n",
    "# Train the models\n",
    "linear_reg_model.fit(X_train_scaled, y_train)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 5: Evaluate the models and compare their respective scores\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    return r2, rmse\n",
    "linear_reg_r2, linear_reg_rmse = evaluate_model(linear_reg_model, X_test_scaled, y_test)\n",
    "ridge_r2, ridge_rmse = evaluate_model(ridge_model, X_test_scaled, y_test)\n",
    "lasso_r2, lasso_rmse = evaluate_model(lasso_model, X_test_scaled, y_test)\n",
    "print(\"Linear Regression R2 Score:\", linear_reg_r2)\n",
    "print(\"Linear Regression RMSE:\", linear_reg_rmse)\n",
    "print(\"Ridge Regression R2 Score:\", ridge_r2)\n",
    "print(\"Ridge Regression RMSE:\", ridge_rmse)\n",
    "print(\"Lasso Regression R2 Score:\", lasso_r2)\n",
    "print(\"Lasso Regression RMSE:\", lasso_rmse)\n",
    "# For example, you can create scatter plots of actual vs. predicted prices.\n",
    "plt.scatter(y_test, linear_reg_model.predict(X_test_scaled), label='Linear Regression',\n",
    "alpha=0.5)\n",
    "\n",
    "plt.scatter(y_test, ridge_model.predict(X_test_scaled), label='Ridge Regression', alpha=0.5)\n",
    "plt.scatter(y_test, lasso_model.predict(X_test_scaled), label='Lasso Regression', alpha=0.5)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5faeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
